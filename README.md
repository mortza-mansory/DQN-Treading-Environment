# 📈 Deep Q-Network (DQN) Trading Visualizer

مدل **Deep Q-Network (DQN)** یک روش **یادگیری تقویتی (Reinforcement Learning)** است که از شبکه‌های عصبی عمیق برای تخمین تابع ارزش-عمل (Q-Function) استفاده می‌کند.  
این پروژه با استفاده از DQN استراتژی‌های معاملاتی **خرید، فروش و نگهداری** را در یک محیط معاملاتی بر اساس داده‌های قیمتی لایت‌کوین یاد می‌گیرد.

---

## 🔎 منطق عملکرد DQN

### 🌍 محیط و حالت‌ها (Environment & States)
- محیط معاملاتی `TradingEnvXY` شامل داده‌های قیمتی (OHLCV) از فایل **litecoin.xlsx** است.  
- حالت‌ها (States) شامل داده‌های نرمال‌سازی‌شده با **z-score** می‌باشند.

### 🎮 اقدامات (Actions)
- **نگهداری (0)** → Hold  
- **خرید (1)** → Buy  
- **فروش (2)** → Sell  

اقدام انتخاب‌شده توسط شبکه Q از لیست `DISCRETE_ACTIONS` استخراج می‌شود.

### 💰 پاداش (Reward)
- محاسبه بر اساس بازده لگاریتمی (**log-return**)  
- اصلاح‌شده با تابع مدیریت سرمایه `money_management`  
- پاداش اضافی بر اساس:
  - صحت پیش‌بینی (±1% تغییر قیمت)  
  - سطح ریسک انتخاب‌شده (Risk Level)  
- نتیجه: سود = پاداش مثبت ✅ | زیان = پاداش منفی ❌

### 🧠 تابع Q و یادگیری
- شبکه Q (**QNetwork**) مقادیر Q را برای هر اقدام پیش‌بینی می‌کند.  
- الگوریتم **Experience Replay**:
  - ذخیره `(state, action, reward, next_state, done)` در حافظه (deque)  
  - آموزش با نمونه‌گیری تصادفی از حافظه  
- استفاده از **Target Network** برای پایداری یادگیری  
- به‌روزرسانی دوره‌ای با `update_target_model`

### 🎲 استراتژی اکتشاف-بهره‌برداری (Exploration vs Exploitation)
- الگوریتم **Epsilon-Greedy**:  
  - با احتمال `ε` → اقدام تصادفی (اکتشاف)  
  - در غیر این صورت → بهترین اقدام بر اساس Q (بهره‌برداری)  
- `ε` با نرخ `epsilon_decay` کاهش می‌یابد تا به `epsilon_min` برسد.

### ⚙️ به‌روزرسانی مدل
- تابع زیان: **MSE (Mean Squared Error)**  
- بهینه‌ساز: **Adam**  
- فرمول به‌روزرسانی:  
target = reward + gamma * max(Q(next_state))
---

## 🖥️ ویژگی‌های محصول (Trading Visualizer)

### 🎛️ رابط کاربری (UI)
- ساخته‌شده با **Flet**  
- شامل:
- دکمه‌های **شروع، توقف، مکث**
- انتخاب مدل و پارامترها
- نمایش لاگ‌ها و معیارها در زمان واقعی  

### 📊 نمایش معیارها (Metrics)
- تعداد خرید، فروش، نگهداری  
- سود و درصد موفقیت  
- موجودی کیف پول و دارایی‌ها  
- معاملات موفق/ناموفق  

### 📈 نمودارها
- **Chart All** → نمایش کل قیمت واقعی  
- **Dynamic Chart** → مقایسه قیمت پیش‌بینی‌شده و واقعی (پنجره متحرک)  
- **Prediction Chart** → نمایش پیش‌بینی قیمت در کل بازه  

### 🛡 مدیریت ریسک
- انتخاب سطح ریسک: خیلی پایین ⬅➡ خیلی بالا  
- مدیریت سرمایه بر اساس `money_management`  
- در نظر گرفتن هزینه‌های تراکنش (اسپرد + کارمزد)

### ⚙️ تنظیمات یادگیری
- پارامترهای قابل تنظیم:  
- `gamma`, `epsilon`, `learning_rate`, `batch_size`  
- ذخیره در **learning_settings.json**

### 💾 ذخیره و بارگذاری مدل
- ذخیره خودکار مدل در: **dqn_model_auto_save.pt**  
- امکان بارگذاری و تست مدل‌های قبلی  
- خروجی تست شامل نمودارها + لاگ‌ها در پوشه مجزا

### 📝 یادداشت‌ها و درس‌های آموخته‌شده
- **AI Notes** → تحلیل اقدامات و پاداش‌ها  
- **Lessons Learned** → بازخورد معاملات موفق/ناموفق  

---

## 📚 فرآیند یادگیری DQN

1. **شروع آموزش**  
 - داده‌های نرمال‌سازی‌شده از litecoin.xlsx  
 - شروع از تاریخ مشخص (مثلاً `2024-01-01` تا `2025-01-01`)

2. **انتخاب اقدام**  
 - تصادفی (اکتشاف) یا بهترین Q (بهره‌برداری)  
 - اقدامات: خرید، فروش، نگهداری

3. **محاسبه پاداش**  
 - بر اساس log-return  
 - صحیح بودن پیش‌بینی (±1%)  
 - اصلاح توسط `money_management`

4. **ذخیره تجربه**  
 - `(state, action, reward, next_state, done)` → حافظه عامل

5. **بازپخش تجربه (Replay)**  
 - نمونه‌گیری تصادفی از حافظه  
 - آموزش با MSE و هدف Q  
 - به‌روزرسانی دوره‌ای شبکه هدف

6. **به‌روزرسانی Epsilon**  
 - کاهش تدریجی `ε` → حرکت به سمت بهره‌برداری

7. **نظارت و بازخورد**  
 - نمایش سود، درصد موفقیت، معاملات  
 - ثبت AI Notes و Lessons Learned  

8. **توقف و ذخیره**  
 - توقف دستی یا خودکار (اتمام داده‌ها / ورشکستگی)  
 - ذخیره مدل نهایی برای تست‌های بعدی  

---

## 📌 خلاصه
این پروژه یک سیستم معاملاتی مبتنی بر **DQN و شبکه عصبی عمیق** است که:  
- از داده‌های قیمتی لایت‌کوین برای یادگیری معاملات استفاده می‌کند.  
- دارای رابط کاربری تعاملی با **نمودارها، معیارها و مدیریت ریسک** است.  
- امکان تنظیم پارامترها، ذخیره و بارگذاری مدل‌ها را فراهم می‌کند.  
- با ترکیب اکتشاف و بهره‌برداری، تجربه‌ها و بازپخش آن‌ها، به استراتژی‌های بهینه معاملاتی می‌رسد.  

---

